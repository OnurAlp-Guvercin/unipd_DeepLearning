Deep Learning Basics and Regularization Techniques with PyTorch
This repository contains two Jupyter notebooks showcasing the implementation of deep learning basics and regularization techniques 
without and with PyTorch.

Notebook 1: Deep Learning Basics without PyTorch
In this notebook, we implement the basics of deep learning without using PyTorch. We load and preprocess the data, 
define the neural network architecture, activation functions, loss functions, and gradient descent algorithm. Finally, we train and test the model.

Notebook 2: Regularization Techniques with PyTorch
In this notebook, we implement regularization techniques using PyTorch. We load and preprocess the data, define the neural network architecture, 
activation functions, and loss functions. Then, we introduce regularization techniques such as L1 and L2 regularization, early stopping, 
and Grid Search. Finally, we train and test the model.

For more details, please refer to the individual notebooks.
